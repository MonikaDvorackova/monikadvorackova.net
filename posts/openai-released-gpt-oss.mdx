---
title: "OpenAI released its first open-weight model: GPT-oss"
date: "2025-08-05"
category: "AI Law"
tags:
  - OpenAI
  - GPT-oss
  - Foundation Models
  - Open Weights
  - EU AI Act
  - Code of Practice
  - Model Transparency
  - Compliance
  - AI Governance
---

OpenAI, together with other major tech players, has taken a landmark step by releasing its first open-weight model, named GPT-oss, as part of a broader commitment to transparency, interoperability, and responsible innovation. This release comes shortly after OpenAI and other industry leaders signed the EU “Code of Practice” – a voluntary yet pivotal framework preparing the ground for compliance with the EU AI Act, the world’s most comprehensive AI regulation to date.

A new era of openness
GPT-oss marks OpenAI’s shift from closed-source dominance toward a more collaborative model development paradigm. While not entirely “open-source” by strict definitions (weights are available, but licensing may restrict certain commercial uses), GPT-oss provides unprecedented visibility into the model’s internals — a move long requested by AI researchers, developers, and policymakers alike.
The model is built on the GPT-4 architecture, with performance optimized for efficiency, safety alignment, and multilingual use. According to OpenAI, GPT-oss is “a smaller sibling of GPT-4o, fine-tuned with safety guardrails and designed for transparent audits.”

EU AI Act implications
The release also strategically aligns with the EU AI Act, which imposes tiered requirements on AI systems depending on their risk classification. Foundation models like GPT fall under systemic risk obligations, which include transparency, documentation, and robustness audits.
By releasing GPT-oss, OpenAI appears to be preemptively complying with expected demands for model documentation, reproducibility, and risk assessment. The Code of Practice, signed by firms including OpenAI, Google DeepMind, Anthropic, and Meta, outlines voluntary commitments around watermarking, red-teaming, cybersecurity, and third-party access for research purposes.

What GPT-oss includes
Model weights: Publicly released with limited licensing
Training data disclosures: Aggregate statistics and dataset composition summaries
Evaluation benchmarks: Openly published across safety, fairness, multilinguality, and hallucination resistance
System card: In-depth model documentation per the EU AI Act’s technical standards
API compatibility: A reference implementation to experiment with integration and finetuning
Reception from the community
The AI research community has largely welcomed the release, viewing it as a long-overdue step toward algorithmic accountability. However, some experts warn that partial openness without open datasets or full licensing may limit the model’s impact outside academia and internal R&D.
Critics have also voiced concerns about model misuse, especially if security and alignment safeguards are not fully testable by third parties. OpenAI maintains that they are releasing GPT-oss as a “research-grade model” rather than a production-ready system, with clear disclaimers around safety limitations.

What’s next?
With the upcoming enforcement phase of the EU AI Act, companies building and deploying foundational AI models will need to adhere to legal mandates that go far beyond voluntary codes. By releasing GPT-oss now, OpenAI positions itself as a proactive and cooperative actor, potentially influencing how regulatory agencies interpret and enforce AI accountability.
This move may also put pressure on other firms to open up their own model ecosystems — creating a domino effect where responsible AI development becomes synonymous with auditable and accessible architectures.

Author’s note: While GPT-oss does not fully open the black box, it opens a significant window into it – and in a time of increasing AI opacity, that matters.